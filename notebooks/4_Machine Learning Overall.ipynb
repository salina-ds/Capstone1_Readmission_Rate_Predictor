{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning_Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-26T22:41:12.430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'my_stop_words' (list)\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import color maps\n",
    "import matplotlib.cm as cm\n",
    "import string\n",
    "# import model related libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, _forest\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import roc_auc_score, fbeta_score, classification_report, confusion_matrix, recall_score, accuracy_score, balanced_accuracy_score\n",
    "from sklearn_pandas import DataFrameMapper, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, KBinsDiscretizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "# import a function that convert items into a callable object\n",
    "from operator import itemgetter\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "%matplotlib inline\n",
    "%run functions.ipynb # import my functions from functions notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-26T22:41:13.409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SUBJECT_ID', 'HADM_ID', 'READMISSION_30DAYS', 'DISCHARGE_LOCATION',\n",
       "       'INSURANCE', 'MARITAL_STATUS', 'GENDER', 'AGE', 'ETHNICITY_GRP',\n",
       "       'CURR_SERVICE', 'NUM_PRESCRIPTION', 'LOS', 'HLOS_CL', 'LOS_RATIO', 'KD',\n",
       "       'HP', 'PUL', 'UT', 'HIV', 'DB', 'MBD', 'TB', 'GA', 'HM', 'HEP', 'HO',\n",
       "       'FR', 'TX', 'LA', 'AF', 'CB', 'PNE', 'HF', 'SP', 'WMCC', 'WCC',\n",
       "       'WOCCMCC', 'WOMCC', 'WCCMCC', 'DRG_SEVERITY', 'DRG_MORTALITY', 'TEXT',\n",
       "       'TEXT_CL', 'AGE_boxcox_lambda_opt', 'NUM_PRESCRIPTION_LOG', 'LOS_LOG',\n",
       "       'LOS_boxcox_lambda_opt', 'HLOS_CL_LOG', 'HLOS_CL_boxcox_lambda_opt',\n",
       "       'LOS_RATIO_LOG', 'LOS_RATIO_boxcox_lambda_opt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load master dataframe with features ready to be transformed and used by the model\n",
    "master = pd.read_csv('../Capstone 1/master.csv')\n",
    "master.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "master.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform features using pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a preparation for building and evaluating the final model, all features need to be transformed and combined into a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-26T22:41:34.630Z"
    }
   },
   "outputs": [],
   "source": [
    "# using datapipeline tools DataFrameMapper to map each feature to the appropriate format before using it in the model\n",
    "mapper = DataFrameMapper([\n",
    "    ('TEXT', TfidfVectorizer(min_df=10, max_features=3000, lowercase=True, #ngram_range=(2, 2),\n",
    "                             tokenizer=tokenizer_better, stop_words=my_stop_words, use_idf=True))\n",
    "    ,('DISCHARGE_LOCATION', LabelEncoder())\n",
    "    ,('INSURANCE',          LabelEncoder())\n",
    "    ,('MARITAL_STATUS',     LabelEncoder())\n",
    "    ,('ETHNICITY_GRP',      LabelEncoder())\n",
    "    ,('CURR_SERVICE',       LabelEncoder())\n",
    "    ,('GENDER',             LabelEncoder())\n",
    "    ,('AGE_boxcox_lambda_opt',        None)\n",
    "#    ,(['AGE'], KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile'))\n",
    "    ,('NUM_PRESCRIPTION_LOG', None)\n",
    "#    ,('LOS_LOG',                None)\n",
    "    ,('LOS_boxcox_lambda_opt', None)\n",
    "#    ,('HLOS_CL_LOG',               None)\n",
    "    ,('HLOS_CL_boxcox_lambda_opt', None)\n",
    "#    ,(['LOS_RATIO'], KBinsDiscretizer(n_bins=5, encode='onehot', strategy='quantile'))\n",
    "#    ,('LOS_RATIO_LOG', None)\n",
    "    ,('LOS_RATIO_boxcox_lambda_opt', None)\n",
    "    ,('KD',                 None)\n",
    "    ,('HP',                 None)\n",
    "    ,('PUL',                None)\n",
    "    ,('UT',                 None)\n",
    "    ,('HIV',                None)\n",
    "    ,('DB',                 None)\n",
    "    ,('MBD',                None)\n",
    "    ,('TB',                 None)\n",
    "    ,('GA',                 None)\n",
    "    ,('HM',                 None)\n",
    "    ,('HF',                 None)\n",
    "    ,('HEP',                None)\n",
    "    ,('HO',                 None)\n",
    "    ,('FR',                 None)\n",
    "    ,('TX',                 None)\n",
    "    ,('LA',                 None)\n",
    "    ,('AF',                 None)\n",
    "    ,('CB',                 None)\n",
    "    ,('SP',                 None)\n",
    "    ,('PNE',                None)\n",
    "    ,('WMCC',               None)\n",
    "    ,('WCC',                None)\n",
    "    ,('WOCCMCC',            None)\n",
    "    ,('WOMCC',              None)\n",
    "    ,('WCCMCC',             None)\n",
    "    ,('READMISSION_30DAYS', None)\n",
    "#    ,('DRG_SEVERITY',       None)\n",
    "#    ,('DRG_MORTALITY',      None)\n",
    "], df_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-04-26T22:41:34.980Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit and transform the master dataset including discharge notes to return a final feature set\n",
    "df = mapper.fit_transform(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8308, 3037)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TEXT_zofran', 'TEXT_zolpidem', 'TEXT_zosyn', 'DISCHARGE_LOCATION',\n",
       "       'INSURANCE', 'MARITAL_STATUS', 'ETHNICITY_GRP', 'CURR_SERVICE',\n",
       "       'GENDER', 'AGE_boxcox_lambda_opt', 'NUM_PRESCRIPTION_LOG',\n",
       "       'LOS_boxcox_lambda_opt', 'HLOS_CL_boxcox_lambda_opt',\n",
       "       'LOS_RATIO_boxcox_lambda_opt', 'KD', 'HP', 'PUL', 'UT', 'HIV', 'DB',\n",
       "       'MBD', 'TB', 'GA', 'HM', 'HF', 'HEP', 'HO', 'FR', 'TX', 'LA', 'AF',\n",
       "       'CB', 'SP', 'PNE', 'WMCC', 'WCC', 'WOCCMCC', 'WOMCC', 'WCCMCC',\n",
       "       'READMISSION_30DAYS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[-40:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance positive and negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test prevalence(n = 1246): 0.2768860353130016\n",
      "Valid prevalence(n = 1246): 0.27046548956661315\n",
      "Train all prevalence(n = 5816): 0.26667812929848694\n",
      "all samples (n = 8308)\n"
     ]
    }
   ],
   "source": [
    "# shuffle the samples\n",
    "df = df.sample(n = len(df), random_state = 42)\n",
    "df = df.reset_index(drop = True)\n",
    "\n",
    "# Save 30% of the data as validation and test data \n",
    "df_valid_test = df.sample(frac=0.30,random_state=42)\n",
    "\n",
    "df_test = df_valid_test.sample(frac = 0.5, random_state = 42)\n",
    "df_valid = df_valid_test.drop(df_test.index)\n",
    "\n",
    "# use the rest of the data as training data\n",
    "df_train_all = df.drop(df_valid_test.index)\n",
    "\n",
    "print('Test prevalence(n = %d):'%len(df_test),df_test.READMISSION_30DAYS.sum()/ len(df_test))\n",
    "print('Valid prevalence(n = %d):'%len(df_valid),df_valid.READMISSION_30DAYS.sum()/ len(df_valid))\n",
    "print('Train all prevalence(n = %d):'%len(df_train_all), df_train_all.READMISSION_30DAYS.sum()/ len(df_train_all))\n",
    "print('all samples (n = %d)'%len(df))\n",
    "assert len(df) == (len(df_test)+len(df_valid)+len(df_train_all)),'math didnt work'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train prevalence (n = 3102): 0.5\n"
     ]
    }
   ],
   "source": [
    "rows_pos = df_train_all.READMISSION_30DAYS == 1\n",
    "df_train_pos = df_train_all.loc[rows_pos]\n",
    "df_train_neg = df_train_all.loc[~rows_pos]\n",
    "\n",
    "# merge the balanced data\n",
    "df_train = pd.concat([df_train_pos, df_train_neg.sample(n = len(df_train_pos), random_state = 42)],axis = 0)\n",
    "\n",
    "# shuffle the order of training samples \n",
    "df_train = df_train.sample(n = len(df_train), random_state = 42).reset_index(drop = True)\n",
    "\n",
    "print('Train prevalence (n = %d):'%len(df_train), df_train.READMISSION_30DAYS.sum()/ len(df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = df_train.drop('READMISSION_30DAYS',axis=1)\n",
    "X_valid_all = df_valid.drop('READMISSION_30DAYS',axis=1)\n",
    "y_train_all = df_train.READMISSION_30DAYS\n",
    "y_valid_all = df_valid.READMISSION_30DAYS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best C-value with L1 penalty with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': np.linspace(start = 0, stop = 2, num = 10)}\n",
    "\n",
    "logistic = LogisticRegression(penalty='l2',solver='liblinear')\n",
    "\n",
    "clf = GridSearchCV(logistic, param_grid=params,  scoring = \"roc_auc\", cv = 3, verbose =1, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   22.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "best_model = clf.fit(X_train_all, y_train_all)\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "#cv_scores = best_model.cv_results_[best_model.cv_results_['mean_test_score']!='nan']\n",
    "#print('Best avg. AUC :', np.mean(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create subsets of features using different C-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression-L1 picked 98 variables and eliminated the other 2938 variables\n",
      "TEXT_tamponade    2.728520\n",
      "TEXT_recommend    2.429873\n",
      "TEXT_subdural     2.321559\n",
      "TEXT_picc         2.319730\n",
      "TEXT_mass         1.820386\n",
      "dtype: float64\n",
      "LogisticRegression-L1 picked 121 variables and eliminated the other 2915 variables\n",
      "TEXT_recommend    3.260077\n",
      "TEXT_tamponade    3.194837\n",
      "TEXT_picc         2.731248\n",
      "TEXT_subdural     2.457508\n",
      "TEXT_mass         1.961444\n",
      "dtype: float64\n",
      "LogisticRegression-L1 picked 162 variables and eliminated the other 2874 variables\n",
      "TEXT_recommend    4.335893\n",
      "TEXT_tamponade    3.910773\n",
      "TEXT_picc         3.393433\n",
      "TEXT_recently     3.202262\n",
      "TEXT_lethargic    2.983532\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "set1 = create_feature_subset(c=0.89, X_train=X_train_all,\n",
    "                           y_train=y_train_all)\n",
    "set2 = create_feature_subset(c=1, X_train=X_train_all,\n",
    "                           y_train=y_train_all)\n",
    "set3 = create_feature_subset(c=1.2, X_train=X_train_all,\n",
    "                           y_train=y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DISCHARGE_LOCATION', 'INSURANCE', 'MARITAL_STATUS', 'ETHNICITY_GRP',\n",
       "       'CURR_SERVICE', 'GENDER', 'AGE_boxcox_lambda_opt',\n",
       "       'NUM_PRESCRIPTION_LOG', 'LOS_boxcox_lambda_opt',\n",
       "       'HLOS_CL_boxcox_lambda_opt', 'LOS_RATIO_boxcox_lambda_opt', 'KD', 'HP',\n",
       "       'PUL', 'HIV', 'DB', 'MBD', 'GA', 'HM', 'HF', 'HEP', 'HO', 'FR', 'TX',\n",
       "       'LA', 'AF', 'SP', 'PNE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set3.columns[~set3.columns.str.contains('TEXT')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find best parameters for several classifiers with 3 subset of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further improve model performance, I will tune the parameters of a few tree-base algorithm and linearSVC model with 3 subsets of important features found using logistic regression with L1 penalty with 3 different C-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s1, X_valid_s1, y_train_s1, y_valid_s1 = create_splits(\n",
    "    features=set1, target=df_train.READMISSION_30DAYS, test_size=0.3, train_size=0.7)\n",
    "X_train_s2, X_valid_s2, y_train_s2, y_valid_s2 = create_splits(\n",
    "    features=set2, target=df_train.READMISSION_30DAYS, test_size=0.3, train_size=0.7)\n",
    "X_train_s3, X_valid_s3, y_train_s3, y_valid_s3 = create_splits(\n",
    "    features=set3, target=df_train.READMISSION_30DAYS, test_size=0.3, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2171, 162) (931,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_s3.shape,y_valid_s1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LogisticRegression' : LogisticRegression(penalty = 'l2', random_state = 0)\n",
    "    ,'RandomForestClassifier': RandomForestClassifier()\n",
    "    ,'AdaBoostClassifier': AdaBoostClassifier()\n",
    "    ,'GradientBoostingClassifier': GradientBoostingClassifier()\n",
    "    ,'XGBClassifier': XGBClassifier()\n",
    "#    'SVC': SVC()\n",
    "}\n",
    "\n",
    "params1 = {\n",
    "    'LogisticRegression' : {'C': np.linspace(start = 0, stop = 2, num = 10), 'solver': ['liblinear','lbfgs'] },\n",
    "    'RandomForestClassifier': { 'n_estimators': [50, 98],'max_depth' : [1, 5],'min_samples_split' : [5, 10] },\n",
    "    'AdaBoostClassifier':  { 'n_estimators': [50, 98],'learning_rate': [0.3, 1.0] },\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [50, 98], 'learning_rate': [0.8, 1] },\n",
    "    'XGBClassifier': { 'n_estimators': [50, 98],'learning_rate': [0.05, 0.3, 1.0], 'max_depth': [1, 3], \n",
    "                      'min_child_weight' : [2, 10] }\n",
    "#    'SVC': {'kernel': ['linear'], 'C': [1, 10]},\n",
    "}\n",
    "\n",
    "params2 = {\n",
    "    'LogisticRegression' : {'C': np.linspace(start = 0, stop = 2, num = 10), 'solver': ['liblinear','lbfgs'] },\n",
    "    'RandomForestClassifier': { 'n_estimators': [100, 121],'max_depth' : [1, 5],'min_samples_split' : [5, 10] },\n",
    "    'AdaBoostClassifier':  { 'n_estimators': [100, 121],'learning_rate': [0.3, 1.0] },\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [100, 121], 'learning_rate': [0.8, 1.0]},\n",
    "    'XGBClassifier': { 'n_estimators': [100, 121],'learning_rate': [0.05, 0.3, 1.0], 'max_depth': [1, 3], \n",
    "                      'min_child_weight' : [2, 10]}\n",
    "}\n",
    "params3 = {\n",
    "    'LogisticRegression' : {'C': np.linspace(start = 0, stop = 2, num = 10), 'solver': ['liblinear','lbfgs'] },\n",
    "    'RandomForestClassifier': { 'n_estimators': [120, 162],'max_depth' : [1, 3],'min_samples_split' : [5, 10] },\n",
    "    'AdaBoostClassifier':  { 'n_estimators': [120, 162],'learning_rate': [0.3, 1.0] },\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [120, 162], 'learning_rate': [0.8, 1.0]},\n",
    "    'XGBClassifier': { 'n_estimators': [120, 162],'learning_rate': [0.05, 0.3, 1.0], 'max_depth': [1, 3], \n",
    "                      'min_child_weight' : [2, 10]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for LogisticRegression.\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=2)]: Done  60 out of  60 | elapsed:    7.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForestClassifier.\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  24 out of  24 | elapsed:    4.9s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  12 out of  12 | elapsed:    5.9s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  12 out of  12 | elapsed:   10.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for XGBClassifier.\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=2)]: Done  72 out of  72 | elapsed:   25.2s finished\n"
     ]
    }
   ],
   "source": [
    "helper1 = EstimatorSelectionHelper(models, params1)\n",
    "helper1.fit(X_train_s1, y_train_s1, scoring='roc_auc', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "RandomForestClassifier\n",
      "AdaBoostClassifier\n",
      "GradientBoostingClassifier\n",
      "XGBClassifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>C</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>solver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.626867</td>\n",
       "      <td>0.638841</td>\n",
       "      <td>0.659532</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.60822</td>\n",
       "      <td>0.633951</td>\n",
       "      <td>0.65889</td>\n",
       "      <td>0.0206932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.627244</td>\n",
       "      <td>0.64386</td>\n",
       "      <td>0.655125</td>\n",
       "      <td>0.0119944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.61779</td>\n",
       "      <td>0.636257</td>\n",
       "      <td>0.653548</td>\n",
       "      <td>0.0146221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.628889</td>\n",
       "      <td>0.644397</td>\n",
       "      <td>0.653204</td>\n",
       "      <td>0.0109997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.607148</td>\n",
       "      <td>0.633531</td>\n",
       "      <td>0.653127</td>\n",
       "      <td>0.0193746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.615279</td>\n",
       "      <td>0.633786</td>\n",
       "      <td>0.653043</td>\n",
       "      <td>0.0154263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.62987</td>\n",
       "      <td>0.637557</td>\n",
       "      <td>0.651719</td>\n",
       "      <td>0.0100264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.639049</td>\n",
       "      <td>0.650051</td>\n",
       "      <td>0.00923633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.609445</td>\n",
       "      <td>0.626025</td>\n",
       "      <td>0.649408</td>\n",
       "      <td>0.0170097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.61961</td>\n",
       "      <td>0.63354</td>\n",
       "      <td>0.649102</td>\n",
       "      <td>0.0120956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.626703</td>\n",
       "      <td>0.63629</td>\n",
       "      <td>0.648819</td>\n",
       "      <td>0.00926547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.613741</td>\n",
       "      <td>0.634147</td>\n",
       "      <td>0.648264</td>\n",
       "      <td>0.0147787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.617049</td>\n",
       "      <td>0.634955</td>\n",
       "      <td>0.647373</td>\n",
       "      <td>0.0129734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.626031</td>\n",
       "      <td>0.635625</td>\n",
       "      <td>0.644641</td>\n",
       "      <td>0.00760851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.606572</td>\n",
       "      <td>0.625071</td>\n",
       "      <td>0.644458</td>\n",
       "      <td>0.0154795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.601016</td>\n",
       "      <td>0.622508</td>\n",
       "      <td>0.643773</td>\n",
       "      <td>0.0174559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.597289</td>\n",
       "      <td>0.624428</td>\n",
       "      <td>0.641691</td>\n",
       "      <td>0.0194258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.630846</td>\n",
       "      <td>0.636802</td>\n",
       "      <td>0.640478</td>\n",
       "      <td>0.00424956</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.629404</td>\n",
       "      <td>0.634163</td>\n",
       "      <td>0.636683</td>\n",
       "      <td>0.00336697</td>\n",
       "      <td>1.77778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.617057</td>\n",
       "      <td>0.628371</td>\n",
       "      <td>0.636615</td>\n",
       "      <td>0.00827454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.59904</td>\n",
       "      <td>0.618649</td>\n",
       "      <td>0.636515</td>\n",
       "      <td>0.0153485</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.588723</td>\n",
       "      <td>0.614167</td>\n",
       "      <td>0.636316</td>\n",
       "      <td>0.0195689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.612868</td>\n",
       "      <td>0.625077</td>\n",
       "      <td>0.636081</td>\n",
       "      <td>0.00951528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.605053</td>\n",
       "      <td>0.622989</td>\n",
       "      <td>0.634677</td>\n",
       "      <td>0.0128756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.611524</td>\n",
       "      <td>0.624118</td>\n",
       "      <td>0.634433</td>\n",
       "      <td>0.00949028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.627634</td>\n",
       "      <td>0.631377</td>\n",
       "      <td>0.633479</td>\n",
       "      <td>0.00265347</td>\n",
       "      <td>1.55556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.625054</td>\n",
       "      <td>0.628158</td>\n",
       "      <td>0.629961</td>\n",
       "      <td>0.00220433</td>\n",
       "      <td>1.33333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.602379</td>\n",
       "      <td>0.612953</td>\n",
       "      <td>0.628038</td>\n",
       "      <td>0.0109502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.594772</td>\n",
       "      <td>0.608464</td>\n",
       "      <td>0.627634</td>\n",
       "      <td>0.0139638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.57807</td>\n",
       "      <td>0.598213</td>\n",
       "      <td>0.625495</td>\n",
       "      <td>0.0200088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.622902</td>\n",
       "      <td>0.623987</td>\n",
       "      <td>0.624993</td>\n",
       "      <td>0.000855383</td>\n",
       "      <td>1.11111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.610811</td>\n",
       "      <td>0.615351</td>\n",
       "      <td>0.620893</td>\n",
       "      <td>0.00417646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.618348</td>\n",
       "      <td>0.619265</td>\n",
       "      <td>0.619896</td>\n",
       "      <td>0.000663493</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.600067</td>\n",
       "      <td>0.609232</td>\n",
       "      <td>0.619697</td>\n",
       "      <td>0.00806658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.597968</td>\n",
       "      <td>0.608875</td>\n",
       "      <td>0.619198</td>\n",
       "      <td>0.00867694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.596014</td>\n",
       "      <td>0.610685</td>\n",
       "      <td>0.618968</td>\n",
       "      <td>0.0104025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.595858</td>\n",
       "      <td>0.605655</td>\n",
       "      <td>0.618693</td>\n",
       "      <td>0.00959994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.586052</td>\n",
       "      <td>0.598977</td>\n",
       "      <td>0.618663</td>\n",
       "      <td>0.0141459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.612395</td>\n",
       "      <td>0.613883</td>\n",
       "      <td>0.615676</td>\n",
       "      <td>0.00135668</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.608823</td>\n",
       "      <td>0.611787</td>\n",
       "      <td>0.61541</td>\n",
       "      <td>0.00272918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.5992</td>\n",
       "      <td>0.607136</td>\n",
       "      <td>0.611247</td>\n",
       "      <td>0.00561245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.603335</td>\n",
       "      <td>0.606556</td>\n",
       "      <td>0.610563</td>\n",
       "      <td>0.00300269</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.580046</td>\n",
       "      <td>0.594506</td>\n",
       "      <td>0.61049</td>\n",
       "      <td>0.0124751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.591493</td>\n",
       "      <td>0.601789</td>\n",
       "      <td>0.609097</td>\n",
       "      <td>0.00749118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.591374</td>\n",
       "      <td>0.596816</td>\n",
       "      <td>0.604351</td>\n",
       "      <td>0.0055009</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.580382</td>\n",
       "      <td>0.593288</td>\n",
       "      <td>0.602978</td>\n",
       "      <td>0.00950096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.576055</td>\n",
       "      <td>0.585711</td>\n",
       "      <td>0.599009</td>\n",
       "      <td>0.00971869</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.583438</td>\n",
       "      <td>0.59273</td>\n",
       "      <td>0.598246</td>\n",
       "      <td>0.00660857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.574379</td>\n",
       "      <td>0.583929</td>\n",
       "      <td>0.597544</td>\n",
       "      <td>0.00988451</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.576063</td>\n",
       "      <td>0.585607</td>\n",
       "      <td>0.597468</td>\n",
       "      <td>0.00889104</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.583209</td>\n",
       "      <td>0.587937</td>\n",
       "      <td>0.5973</td>\n",
       "      <td>0.00662086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.575213</td>\n",
       "      <td>0.584036</td>\n",
       "      <td>0.594301</td>\n",
       "      <td>0.00785901</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.577448</td>\n",
       "      <td>0.584888</td>\n",
       "      <td>0.592332</td>\n",
       "      <td>0.00607667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.573002</td>\n",
       "      <td>0.582788</td>\n",
       "      <td>0.591935</td>\n",
       "      <td>0.00774289</td>\n",
       "      <td>1.77778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.576996</td>\n",
       "      <td>0.583382</td>\n",
       "      <td>0.591195</td>\n",
       "      <td>0.00588405</td>\n",
       "      <td>1.11111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.576774</td>\n",
       "      <td>0.582046</td>\n",
       "      <td>0.589585</td>\n",
       "      <td>0.00547019</td>\n",
       "      <td>1.33333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.579292</td>\n",
       "      <td>0.582949</td>\n",
       "      <td>0.587143</td>\n",
       "      <td>0.00322775</td>\n",
       "      <td>1.55556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     estimator min_score mean_score max_score    std_score  \\\n",
       "41               XGBClassifier  0.626867   0.638841  0.659532     0.014691   \n",
       "29          AdaBoostClassifier   0.60822   0.633951   0.65889    0.0206932   \n",
       "45               XGBClassifier  0.627244    0.64386  0.655125    0.0119944   \n",
       "48               XGBClassifier   0.61779   0.636257  0.653548    0.0146221   \n",
       "47               XGBClassifier  0.628889   0.644397  0.653204    0.0109997   \n",
       "43               XGBClassifier  0.607148   0.633531  0.653127    0.0193746   \n",
       "49               XGBClassifier  0.615279   0.633786  0.653043    0.0154263   \n",
       "50               XGBClassifier   0.62987   0.637557  0.651719    0.0100264   \n",
       "27      RandomForestClassifier  0.627451   0.639049  0.650051   0.00923633   \n",
       "40               XGBClassifier  0.609445   0.626025  0.649408    0.0170097   \n",
       "28          AdaBoostClassifier   0.61961    0.63354  0.649102    0.0120956   \n",
       "51               XGBClassifier  0.626703    0.63629  0.648819   0.00926547   \n",
       "46               XGBClassifier  0.613741   0.634147  0.648264    0.0147787   \n",
       "44               XGBClassifier  0.617049   0.634955  0.647373    0.0129734   \n",
       "25      RandomForestClassifier  0.626031   0.635625  0.644641   0.00760851   \n",
       "24      RandomForestClassifier  0.606572   0.625071  0.644458    0.0154795   \n",
       "42               XGBClassifier  0.601016   0.622508  0.643773    0.0174559   \n",
       "52               XGBClassifier  0.597289   0.624428  0.641691    0.0194258   \n",
       "18          LogisticRegression  0.630846   0.636802  0.640478   0.00424956   \n",
       "16          LogisticRegression  0.629404   0.634163  0.636683   0.00336697   \n",
       "30          AdaBoostClassifier  0.617057   0.628371  0.636615   0.00827454   \n",
       "53               XGBClassifier   0.59904   0.618649  0.636515    0.0153485   \n",
       "31          AdaBoostClassifier  0.588723   0.614167  0.636316    0.0195689   \n",
       "54               XGBClassifier  0.612868   0.625077  0.636081   0.00951528   \n",
       "55               XGBClassifier  0.605053   0.622989  0.634677    0.0128756   \n",
       "26      RandomForestClassifier  0.611524   0.624118  0.634433   0.00949028   \n",
       "14          LogisticRegression  0.627634   0.631377  0.633479   0.00265347   \n",
       "12          LogisticRegression  0.625054   0.628158  0.629961   0.00220433   \n",
       "21      RandomForestClassifier  0.602379   0.612953  0.628038    0.0109502   \n",
       "57               XGBClassifier  0.594772   0.608464  0.627634    0.0139638   \n",
       "35  GradientBoostingClassifier   0.57807   0.598213  0.625495    0.0200088   \n",
       "10          LogisticRegression  0.622902   0.623987  0.624993  0.000855383   \n",
       "23      RandomForestClassifier  0.610811   0.615351  0.620893   0.00417646   \n",
       "8           LogisticRegression  0.618348   0.619265  0.619896  0.000663493   \n",
       "58               XGBClassifier  0.600067   0.609232  0.619697   0.00806658   \n",
       "37               XGBClassifier  0.597968   0.608875  0.619198   0.00867694   \n",
       "39               XGBClassifier  0.596014   0.610685  0.618968    0.0104025   \n",
       "32  GradientBoostingClassifier  0.595858   0.605655  0.618693   0.00959994   \n",
       "22      RandomForestClassifier  0.586052   0.598977  0.618663    0.0141459   \n",
       "6           LogisticRegression  0.612395   0.613883  0.615676   0.00135668   \n",
       "59               XGBClassifier  0.608823   0.611787   0.61541   0.00272918   \n",
       "56               XGBClassifier    0.5992   0.607136  0.611247   0.00561245   \n",
       "4           LogisticRegression  0.603335   0.606556  0.610563   0.00300269   \n",
       "34  GradientBoostingClassifier  0.580046   0.594506   0.61049    0.0124751   \n",
       "33  GradientBoostingClassifier  0.591493   0.601789  0.609097   0.00749118   \n",
       "2           LogisticRegression  0.591374   0.596816  0.604351    0.0055009   \n",
       "38               XGBClassifier  0.580382   0.593288  0.602978   0.00950096   \n",
       "7           LogisticRegression  0.576055   0.585711  0.599009   0.00971869   \n",
       "36               XGBClassifier  0.583438    0.59273  0.598246   0.00660857   \n",
       "5           LogisticRegression  0.574379   0.583929  0.597544   0.00988451   \n",
       "19          LogisticRegression  0.576063   0.585607  0.597468   0.00889104   \n",
       "20      RandomForestClassifier  0.583209   0.587937    0.5973   0.00662086   \n",
       "3           LogisticRegression  0.575213   0.584036  0.594301   0.00785901   \n",
       "9           LogisticRegression  0.577448   0.584888  0.592332   0.00607667   \n",
       "17          LogisticRegression  0.573002   0.582788  0.591935   0.00774289   \n",
       "11          LogisticRegression  0.576996   0.583382  0.591195   0.00588405   \n",
       "13          LogisticRegression  0.576774   0.582046  0.589585   0.00547019   \n",
       "15          LogisticRegression  0.579292   0.582949  0.587143   0.00322775   \n",
       "0           LogisticRegression       NaN        NaN       NaN          NaN   \n",
       "1           LogisticRegression       NaN        NaN       NaN          NaN   \n",
       "\n",
       "           C learning_rate max_depth min_child_weight min_samples_split  \\\n",
       "41       NaN          0.05         3                2               NaN   \n",
       "29       NaN           0.3       NaN              NaN               NaN   \n",
       "45       NaN           0.3         1                2               NaN   \n",
       "48       NaN           0.3         3                2               NaN   \n",
       "47       NaN           0.3         1               10               NaN   \n",
       "43       NaN          0.05         3               10               NaN   \n",
       "49       NaN           0.3         3                2               NaN   \n",
       "50       NaN           0.3         3               10               NaN   \n",
       "27       NaN           NaN         5              NaN                10   \n",
       "40       NaN          0.05         3                2               NaN   \n",
       "28       NaN           0.3       NaN              NaN               NaN   \n",
       "51       NaN           0.3         3               10               NaN   \n",
       "46       NaN           0.3         1               10               NaN   \n",
       "44       NaN           0.3         1                2               NaN   \n",
       "25       NaN           NaN         5              NaN                 5   \n",
       "24       NaN           NaN         5              NaN                 5   \n",
       "42       NaN          0.05         3               10               NaN   \n",
       "52       NaN             1         1                2               NaN   \n",
       "18         2           NaN       NaN              NaN               NaN   \n",
       "16   1.77778           NaN       NaN              NaN               NaN   \n",
       "30       NaN             1       NaN              NaN               NaN   \n",
       "53       NaN             1         1                2               NaN   \n",
       "31       NaN             1       NaN              NaN               NaN   \n",
       "54       NaN             1         1               10               NaN   \n",
       "55       NaN             1         1               10               NaN   \n",
       "26       NaN           NaN         5              NaN                10   \n",
       "14   1.55556           NaN       NaN              NaN               NaN   \n",
       "12   1.33333           NaN       NaN              NaN               NaN   \n",
       "21       NaN           NaN         1              NaN                 5   \n",
       "57       NaN             1         3                2               NaN   \n",
       "35       NaN             1       NaN              NaN               NaN   \n",
       "10   1.11111           NaN       NaN              NaN               NaN   \n",
       "23       NaN           NaN         1              NaN                10   \n",
       "8   0.888889           NaN       NaN              NaN               NaN   \n",
       "58       NaN             1         3               10               NaN   \n",
       "37       NaN          0.05         1                2               NaN   \n",
       "39       NaN          0.05         1               10               NaN   \n",
       "32       NaN           0.8       NaN              NaN               NaN   \n",
       "22       NaN           NaN         1              NaN                10   \n",
       "6   0.666667           NaN       NaN              NaN               NaN   \n",
       "59       NaN             1         3               10               NaN   \n",
       "56       NaN             1         3                2               NaN   \n",
       "4   0.444444           NaN       NaN              NaN               NaN   \n",
       "34       NaN             1       NaN              NaN               NaN   \n",
       "33       NaN           0.8       NaN              NaN               NaN   \n",
       "2   0.222222           NaN       NaN              NaN               NaN   \n",
       "38       NaN          0.05         1               10               NaN   \n",
       "7   0.666667           NaN       NaN              NaN               NaN   \n",
       "36       NaN          0.05         1                2               NaN   \n",
       "5   0.444444           NaN       NaN              NaN               NaN   \n",
       "19         2           NaN       NaN              NaN               NaN   \n",
       "20       NaN           NaN         1              NaN                 5   \n",
       "3   0.222222           NaN       NaN              NaN               NaN   \n",
       "9   0.888889           NaN       NaN              NaN               NaN   \n",
       "17   1.77778           NaN       NaN              NaN               NaN   \n",
       "11   1.11111           NaN       NaN              NaN               NaN   \n",
       "13   1.33333           NaN       NaN              NaN               NaN   \n",
       "15   1.55556           NaN       NaN              NaN               NaN   \n",
       "0          0           NaN       NaN              NaN               NaN   \n",
       "1          0           NaN       NaN              NaN               NaN   \n",
       "\n",
       "   n_estimators     solver  \n",
       "41           95        NaN  \n",
       "29           95        NaN  \n",
       "45           95        NaN  \n",
       "48           50        NaN  \n",
       "47           95        NaN  \n",
       "43           95        NaN  \n",
       "49           95        NaN  \n",
       "50           50        NaN  \n",
       "27           95        NaN  \n",
       "40           50        NaN  \n",
       "28           50        NaN  \n",
       "51           95        NaN  \n",
       "46           50        NaN  \n",
       "44           50        NaN  \n",
       "25           95        NaN  \n",
       "24           50        NaN  \n",
       "42           50        NaN  \n",
       "52           50        NaN  \n",
       "18          NaN  liblinear  \n",
       "16          NaN  liblinear  \n",
       "30           50        NaN  \n",
       "53           95        NaN  \n",
       "31           95        NaN  \n",
       "54           50        NaN  \n",
       "55           95        NaN  \n",
       "26           50        NaN  \n",
       "14          NaN  liblinear  \n",
       "12          NaN  liblinear  \n",
       "21           95        NaN  \n",
       "57           95        NaN  \n",
       "35           95        NaN  \n",
       "10          NaN  liblinear  \n",
       "23           95        NaN  \n",
       "8           NaN  liblinear  \n",
       "58           50        NaN  \n",
       "37           95        NaN  \n",
       "39           95        NaN  \n",
       "32           50        NaN  \n",
       "22           50        NaN  \n",
       "6           NaN  liblinear  \n",
       "59           95        NaN  \n",
       "56           50        NaN  \n",
       "4           NaN  liblinear  \n",
       "34           50        NaN  \n",
       "33           95        NaN  \n",
       "2           NaN  liblinear  \n",
       "38           50        NaN  \n",
       "7           NaN      lbfgs  \n",
       "36           50        NaN  \n",
       "5           NaN      lbfgs  \n",
       "19          NaN      lbfgs  \n",
       "20           50        NaN  \n",
       "3           NaN      lbfgs  \n",
       "9           NaN      lbfgs  \n",
       "17          NaN      lbfgs  \n",
       "11          NaN      lbfgs  \n",
       "13          NaN      lbfgs  \n",
       "15          NaN      lbfgs  \n",
       "0           NaN  liblinear  \n",
       "1           NaN      lbfgs  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper1.score_summary(sort_by='max_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForestClassifier.\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  24 out of  24 | elapsed:   28.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  12 out of  12 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  12 out of  12 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for XGBClassifier.\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=2)]: Done  72 out of  72 | elapsed: 11.6min finished\n"
     ]
    }
   ],
   "source": [
    "helper2 = EstimatorSelectionHelper(models, params2)\n",
    "helper2.fit(X_train_s2, y_train_s2, scoring='roc_auc', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "AdaBoostClassifier\n",
      "GradientBoostingClassifier\n",
      "XGBClassifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.683662</td>\n",
       "      <td>0.69048</td>\n",
       "      <td>0.695975</td>\n",
       "      <td>0.00511299</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.679337</td>\n",
       "      <td>0.686184</td>\n",
       "      <td>0.692219</td>\n",
       "      <td>0.00529037</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.670177</td>\n",
       "      <td>0.6787</td>\n",
       "      <td>0.690064</td>\n",
       "      <td>0.00836369</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.664903</td>\n",
       "      <td>0.676753</td>\n",
       "      <td>0.68763</td>\n",
       "      <td>0.00930394</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.665665</td>\n",
       "      <td>0.677431</td>\n",
       "      <td>0.687144</td>\n",
       "      <td>0.00888811</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.662629</td>\n",
       "      <td>0.673444</td>\n",
       "      <td>0.686922</td>\n",
       "      <td>0.0100948</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.67085</td>\n",
       "      <td>0.677226</td>\n",
       "      <td>0.685908</td>\n",
       "      <td>0.00636024</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.661295</td>\n",
       "      <td>0.671806</td>\n",
       "      <td>0.685548</td>\n",
       "      <td>0.0101615</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.671296</td>\n",
       "      <td>0.678009</td>\n",
       "      <td>0.684327</td>\n",
       "      <td>0.00532707</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.660915</td>\n",
       "      <td>0.671579</td>\n",
       "      <td>0.683435</td>\n",
       "      <td>0.0092326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.661581</td>\n",
       "      <td>0.671508</td>\n",
       "      <td>0.682094</td>\n",
       "      <td>0.00838752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.66149</td>\n",
       "      <td>0.669854</td>\n",
       "      <td>0.680543</td>\n",
       "      <td>0.00795007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.661883</td>\n",
       "      <td>0.669295</td>\n",
       "      <td>0.679479</td>\n",
       "      <td>0.00744653</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.666331</td>\n",
       "      <td>0.671834</td>\n",
       "      <td>0.679467</td>\n",
       "      <td>0.00557055</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.667723</td>\n",
       "      <td>0.673994</td>\n",
       "      <td>0.678225</td>\n",
       "      <td>0.00452359</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.676339</td>\n",
       "      <td>0.676778</td>\n",
       "      <td>0.677365</td>\n",
       "      <td>0.000431743</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.656648</td>\n",
       "      <td>0.664168</td>\n",
       "      <td>0.677228</td>\n",
       "      <td>0.00926981</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.656337</td>\n",
       "      <td>0.664311</td>\n",
       "      <td>0.677218</td>\n",
       "      <td>0.00921104</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.659226</td>\n",
       "      <td>0.669801</td>\n",
       "      <td>0.676995</td>\n",
       "      <td>0.00763782</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.669472</td>\n",
       "      <td>0.672313</td>\n",
       "      <td>0.676621</td>\n",
       "      <td>0.00309772</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.664174</td>\n",
       "      <td>0.671407</td>\n",
       "      <td>0.676404</td>\n",
       "      <td>0.00523707</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.666076</td>\n",
       "      <td>0.671089</td>\n",
       "      <td>0.675879</td>\n",
       "      <td>0.00400509</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.658416</td>\n",
       "      <td>0.668878</td>\n",
       "      <td>0.674617</td>\n",
       "      <td>0.00740946</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.648529</td>\n",
       "      <td>0.660877</td>\n",
       "      <td>0.669453</td>\n",
       "      <td>0.00894906</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.66352</td>\n",
       "      <td>0.666824</td>\n",
       "      <td>0.669021</td>\n",
       "      <td>0.00237833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.635116</td>\n",
       "      <td>0.650839</td>\n",
       "      <td>0.662064</td>\n",
       "      <td>0.0114518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.64453</td>\n",
       "      <td>0.654993</td>\n",
       "      <td>0.661611</td>\n",
       "      <td>0.00748462</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.638832</td>\n",
       "      <td>0.650108</td>\n",
       "      <td>0.660783</td>\n",
       "      <td>0.00897137</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.638832</td>\n",
       "      <td>0.650237</td>\n",
       "      <td>0.660574</td>\n",
       "      <td>0.00890796</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.646336</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>0.657963</td>\n",
       "      <td>0.00477284</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.645823</td>\n",
       "      <td>0.651843</td>\n",
       "      <td>0.654869</td>\n",
       "      <td>0.00425705</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.64537</td>\n",
       "      <td>0.648607</td>\n",
       "      <td>0.654708</td>\n",
       "      <td>0.00431712</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.633459</td>\n",
       "      <td>0.645554</td>\n",
       "      <td>0.654517</td>\n",
       "      <td>0.00887751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.625703</td>\n",
       "      <td>0.643547</td>\n",
       "      <td>0.652875</td>\n",
       "      <td>0.0126218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0.636034</td>\n",
       "      <td>0.65212</td>\n",
       "      <td>0.0119536</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.628614</td>\n",
       "      <td>0.643929</td>\n",
       "      <td>0.651871</td>\n",
       "      <td>0.010832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.642578</td>\n",
       "      <td>0.645352</td>\n",
       "      <td>0.647707</td>\n",
       "      <td>0.00211448</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.626044</td>\n",
       "      <td>0.633504</td>\n",
       "      <td>0.644165</td>\n",
       "      <td>0.00773644</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.625063</td>\n",
       "      <td>0.634901</td>\n",
       "      <td>0.643874</td>\n",
       "      <td>0.00770392</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.64116</td>\n",
       "      <td>0.64253</td>\n",
       "      <td>0.643384</td>\n",
       "      <td>0.000978557</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     estimator min_score mean_score max_score    std_score  \\\n",
       "27               XGBClassifier  0.683662    0.69048  0.695975   0.00511299   \n",
       "25               XGBClassifier  0.679337   0.686184  0.692219   0.00529037   \n",
       "23               XGBClassifier  0.670177     0.6787  0.690064   0.00836369   \n",
       "31               XGBClassifier  0.664903   0.676753   0.68763   0.00930394   \n",
       "21               XGBClassifier  0.665665   0.677431  0.687144   0.00888811   \n",
       "20               XGBClassifier  0.662629   0.673444  0.686922    0.0100948   \n",
       "24               XGBClassifier   0.67085   0.677226  0.685908   0.00636024   \n",
       "22               XGBClassifier  0.661295   0.671806  0.685548    0.0101615   \n",
       "26               XGBClassifier  0.671296   0.678009  0.684327   0.00532707   \n",
       "5       RandomForestClassifier  0.660915   0.671579  0.683435    0.0092326   \n",
       "7       RandomForestClassifier  0.661581   0.671508  0.682094   0.00838752   \n",
       "4       RandomForestClassifier   0.66149   0.669854  0.680543   0.00795007   \n",
       "8           AdaBoostClassifier  0.661883   0.669295  0.679479   0.00744653   \n",
       "9           AdaBoostClassifier  0.666331   0.671834  0.679467   0.00557055   \n",
       "30               XGBClassifier  0.667723   0.673994  0.678225   0.00452359   \n",
       "35               XGBClassifier  0.676339   0.676778  0.677365  0.000431743   \n",
       "17               XGBClassifier  0.656648   0.664168  0.677228   0.00926981   \n",
       "19               XGBClassifier  0.656337   0.664311  0.677218   0.00921104   \n",
       "6       RandomForestClassifier  0.659226   0.669801  0.676995   0.00763782   \n",
       "33               XGBClassifier  0.669472   0.672313  0.676621   0.00309772   \n",
       "29               XGBClassifier  0.664174   0.671407  0.676404   0.00523707   \n",
       "34               XGBClassifier  0.666076   0.671089  0.675879   0.00400509   \n",
       "28               XGBClassifier  0.658416   0.668878  0.674617   0.00740946   \n",
       "11          AdaBoostClassifier  0.648529   0.660877  0.669453   0.00894906   \n",
       "32               XGBClassifier   0.66352   0.666824  0.669021   0.00237833   \n",
       "1       RandomForestClassifier  0.635116   0.650839  0.662064    0.0114518   \n",
       "13  GradientBoostingClassifier   0.64453   0.654993  0.661611   0.00748462   \n",
       "16               XGBClassifier  0.638832   0.650108  0.660783   0.00897137   \n",
       "18               XGBClassifier  0.638832   0.650237  0.660574   0.00890796   \n",
       "37               XGBClassifier  0.646336     0.6525  0.657963   0.00477284   \n",
       "10          AdaBoostClassifier  0.645823   0.651843  0.654869   0.00425705   \n",
       "36               XGBClassifier   0.64537   0.648607  0.654708   0.00431712   \n",
       "3       RandomForestClassifier  0.633459   0.645554  0.654517   0.00887751   \n",
       "0       RandomForestClassifier  0.625703   0.643547  0.652875    0.0126218   \n",
       "39               XGBClassifier   0.62349   0.636034   0.65212    0.0119536   \n",
       "2       RandomForestClassifier  0.628614   0.643929  0.651871     0.010832   \n",
       "12  GradientBoostingClassifier  0.642578   0.645352  0.647707   0.00211448   \n",
       "38               XGBClassifier  0.626044   0.633504  0.644165   0.00773644   \n",
       "14  GradientBoostingClassifier  0.625063   0.634901  0.643874   0.00770392   \n",
       "15  GradientBoostingClassifier   0.64116    0.64253  0.643384  0.000978557   \n",
       "\n",
       "   learning_rate max_depth min_child_weight min_samples_split n_estimators  \n",
       "27           0.3         1               10               NaN          307  \n",
       "25           0.3         1                2               NaN          307  \n",
       "23          0.05         3               10               NaN          307  \n",
       "31           0.3         3               10               NaN          307  \n",
       "21          0.05         3                2               NaN          307  \n",
       "20          0.05         3                2               NaN          154  \n",
       "24           0.3         1                2               NaN          154  \n",
       "22          0.05         3               10               NaN          154  \n",
       "26           0.3         1               10               NaN          154  \n",
       "5            NaN         5              NaN                 5          307  \n",
       "7            NaN         5              NaN                10          307  \n",
       "4            NaN         5              NaN                 5          154  \n",
       "8            0.3       NaN              NaN               NaN          154  \n",
       "9            0.3       NaN              NaN               NaN          307  \n",
       "30           0.3         3               10               NaN          154  \n",
       "35             1         1               10               NaN          307  \n",
       "17          0.05         1                2               NaN          307  \n",
       "19          0.05         1               10               NaN          307  \n",
       "6            NaN         5              NaN                10          154  \n",
       "33             1         1                2               NaN          307  \n",
       "29           0.3         3                2               NaN          307  \n",
       "34             1         1               10               NaN          154  \n",
       "28           0.3         3                2               NaN          154  \n",
       "11             1       NaN              NaN               NaN          307  \n",
       "32             1         1                2               NaN          154  \n",
       "1            NaN         1              NaN                 5          307  \n",
       "13           0.8       NaN              NaN               NaN          307  \n",
       "16          0.05         1                2               NaN          154  \n",
       "18          0.05         1               10               NaN          154  \n",
       "37             1         3                2               NaN          307  \n",
       "10             1       NaN              NaN               NaN          154  \n",
       "36             1         3                2               NaN          154  \n",
       "3            NaN         1              NaN                10          307  \n",
       "0            NaN         1              NaN                 5          154  \n",
       "39             1         3               10               NaN          307  \n",
       "2            NaN         1              NaN                10          154  \n",
       "12           0.8       NaN              NaN               NaN          154  \n",
       "38             1         3               10               NaN          154  \n",
       "14             1       NaN              NaN               NaN          154  \n",
       "15             1       NaN              NaN               NaN          307  "
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper2.score_summary(sort_by='max_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for LogisticRegression.\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=2)]: Done  60 out of  60 | elapsed:    7.3s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForestClassifier.\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  24 out of  24 | elapsed:    8.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  12 out of  12 | elapsed:   14.3s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  12 out of  12 | elapsed:   27.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for XGBClassifier.\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   56.8s\n",
      "[Parallel(n_jobs=2)]: Done  72 out of  72 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "helper3 = EstimatorSelectionHelper(models, params3)\n",
    "helper3.fit(X_train_s3, y_train_s3, scoring='roc_auc', n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "RandomForestClassifier\n",
      "AdaBoostClassifier\n",
      "GradientBoostingClassifier\n",
      "XGBClassifier\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>min_score</th>\n",
       "      <th>mean_score</th>\n",
       "      <th>max_score</th>\n",
       "      <th>std_score</th>\n",
       "      <th>C</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>solver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.642419</td>\n",
       "      <td>0.663738</td>\n",
       "      <td>0.682921</td>\n",
       "      <td>0.0166038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.64836</td>\n",
       "      <td>0.663671</td>\n",
       "      <td>0.674301</td>\n",
       "      <td>0.0110959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.642217</td>\n",
       "      <td>0.663598</td>\n",
       "      <td>0.68278</td>\n",
       "      <td>0.0166326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.647123</td>\n",
       "      <td>0.660039</td>\n",
       "      <td>0.671569</td>\n",
       "      <td>0.0100279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.638569</td>\n",
       "      <td>0.659105</td>\n",
       "      <td>0.674423</td>\n",
       "      <td>0.0150954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.638165</td>\n",
       "      <td>0.658038</td>\n",
       "      <td>0.671764</td>\n",
       "      <td>0.0143895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.626771</td>\n",
       "      <td>0.657795</td>\n",
       "      <td>0.684513</td>\n",
       "      <td>0.0237686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.649733</td>\n",
       "      <td>0.657387</td>\n",
       "      <td>0.664254</td>\n",
       "      <td>0.00595396</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.639221</td>\n",
       "      <td>0.655068</td>\n",
       "      <td>0.679489</td>\n",
       "      <td>0.0175216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.644659</td>\n",
       "      <td>0.654368</td>\n",
       "      <td>0.66446</td>\n",
       "      <td>0.00808855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.647284</td>\n",
       "      <td>0.654012</td>\n",
       "      <td>0.659938</td>\n",
       "      <td>0.00519716</td>\n",
       "      <td>1.77778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.632983</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.683966</td>\n",
       "      <td>0.0222482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.64166</td>\n",
       "      <td>0.652829</td>\n",
       "      <td>0.667628</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.63739</td>\n",
       "      <td>0.652134</td>\n",
       "      <td>0.672621</td>\n",
       "      <td>0.0149454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.62613</td>\n",
       "      <td>0.651923</td>\n",
       "      <td>0.675265</td>\n",
       "      <td>0.0201339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.629061</td>\n",
       "      <td>0.650791</td>\n",
       "      <td>0.680407</td>\n",
       "      <td>0.0216914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.644392</td>\n",
       "      <td>0.649938</td>\n",
       "      <td>0.654643</td>\n",
       "      <td>0.00422702</td>\n",
       "      <td>1.55556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.631503</td>\n",
       "      <td>0.648598</td>\n",
       "      <td>0.66723</td>\n",
       "      <td>0.0146262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.629236</td>\n",
       "      <td>0.648288</td>\n",
       "      <td>0.676895</td>\n",
       "      <td>0.0205964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.634494</td>\n",
       "      <td>0.648201</td>\n",
       "      <td>0.663435</td>\n",
       "      <td>0.0118643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.631743</td>\n",
       "      <td>0.646585</td>\n",
       "      <td>0.672962</td>\n",
       "      <td>0.0186999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.637356</td>\n",
       "      <td>0.646445</td>\n",
       "      <td>0.65452</td>\n",
       "      <td>0.00704396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.627588</td>\n",
       "      <td>0.645727</td>\n",
       "      <td>0.65667</td>\n",
       "      <td>0.0129173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.640744</td>\n",
       "      <td>0.645269</td>\n",
       "      <td>0.648307</td>\n",
       "      <td>0.00326181</td>\n",
       "      <td>1.33333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.63048</td>\n",
       "      <td>0.643028</td>\n",
       "      <td>0.655882</td>\n",
       "      <td>0.0103727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.634647</td>\n",
       "      <td>0.64184</td>\n",
       "      <td>0.648146</td>\n",
       "      <td>0.00554675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.636669</td>\n",
       "      <td>0.639478</td>\n",
       "      <td>0.64096</td>\n",
       "      <td>0.00198744</td>\n",
       "      <td>1.11111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.625428</td>\n",
       "      <td>0.639413</td>\n",
       "      <td>0.656456</td>\n",
       "      <td>0.0128502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.624413</td>\n",
       "      <td>0.63828</td>\n",
       "      <td>0.646998</td>\n",
       "      <td>0.00991314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.627038</td>\n",
       "      <td>0.6357</td>\n",
       "      <td>0.645651</td>\n",
       "      <td>0.00765319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.621285</td>\n",
       "      <td>0.634997</td>\n",
       "      <td>0.644041</td>\n",
       "      <td>0.00985945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.632991</td>\n",
       "      <td>0.634444</td>\n",
       "      <td>0.63731</td>\n",
       "      <td>0.00202622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.609968</td>\n",
       "      <td>0.633701</td>\n",
       "      <td>0.651276</td>\n",
       "      <td>0.017417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.620323</td>\n",
       "      <td>0.63332</td>\n",
       "      <td>0.643394</td>\n",
       "      <td>0.00964258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.609563</td>\n",
       "      <td>0.633288</td>\n",
       "      <td>0.659287</td>\n",
       "      <td>0.0203634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.631007</td>\n",
       "      <td>0.632557</td>\n",
       "      <td>0.633822</td>\n",
       "      <td>0.00116706</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.615653</td>\n",
       "      <td>0.630839</td>\n",
       "      <td>0.656448</td>\n",
       "      <td>0.0182129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.616015</td>\n",
       "      <td>0.629901</td>\n",
       "      <td>0.640042</td>\n",
       "      <td>0.0101598</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.622963</td>\n",
       "      <td>0.623981</td>\n",
       "      <td>0.624864</td>\n",
       "      <td>0.00078193</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.616019</td>\n",
       "      <td>0.621422</td>\n",
       "      <td>0.627187</td>\n",
       "      <td>0.00456651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.601238</td>\n",
       "      <td>0.621298</td>\n",
       "      <td>0.635133</td>\n",
       "      <td>0.014521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.598575</td>\n",
       "      <td>0.620451</td>\n",
       "      <td>0.634188</td>\n",
       "      <td>0.0156371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.607781</td>\n",
       "      <td>0.617884</td>\n",
       "      <td>0.623265</td>\n",
       "      <td>0.00714847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.608873</td>\n",
       "      <td>0.61757</td>\n",
       "      <td>0.624068</td>\n",
       "      <td>0.00639561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.604897</td>\n",
       "      <td>0.615615</td>\n",
       "      <td>0.625825</td>\n",
       "      <td>0.00855122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>162</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.611492</td>\n",
       "      <td>0.613841</td>\n",
       "      <td>0.616134</td>\n",
       "      <td>0.00189535</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.591829</td>\n",
       "      <td>0.61324</td>\n",
       "      <td>0.624615</td>\n",
       "      <td>0.0151501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.587403</td>\n",
       "      <td>0.611857</td>\n",
       "      <td>0.624776</td>\n",
       "      <td>0.0173008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.59507</td>\n",
       "      <td>0.600744</td>\n",
       "      <td>0.607251</td>\n",
       "      <td>0.00500754</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.572741</td>\n",
       "      <td>0.58497</td>\n",
       "      <td>0.600345</td>\n",
       "      <td>0.0114865</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.578612</td>\n",
       "      <td>0.584058</td>\n",
       "      <td>0.59437</td>\n",
       "      <td>0.00729547</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.575198</td>\n",
       "      <td>0.582986</td>\n",
       "      <td>0.590127</td>\n",
       "      <td>0.00611192</td>\n",
       "      <td>1.77778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.568709</td>\n",
       "      <td>0.581148</td>\n",
       "      <td>0.597888</td>\n",
       "      <td>0.0122941</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.571976</td>\n",
       "      <td>0.580722</td>\n",
       "      <td>0.589242</td>\n",
       "      <td>0.00705039</td>\n",
       "      <td>1.33333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.574723</td>\n",
       "      <td>0.580676</td>\n",
       "      <td>0.591874</td>\n",
       "      <td>0.00792391</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.574433</td>\n",
       "      <td>0.580085</td>\n",
       "      <td>0.585197</td>\n",
       "      <td>0.00441125</td>\n",
       "      <td>1.55556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.577337</td>\n",
       "      <td>0.578539</td>\n",
       "      <td>0.580863</td>\n",
       "      <td>0.0016435</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.571408</td>\n",
       "      <td>0.577469</td>\n",
       "      <td>0.582061</td>\n",
       "      <td>0.0044716</td>\n",
       "      <td>1.11111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     estimator min_score mean_score max_score   std_score  \\\n",
       "45               XGBClassifier  0.642419   0.663738  0.682921   0.0166038   \n",
       "48               XGBClassifier   0.64836   0.663671  0.674301   0.0110959   \n",
       "47               XGBClassifier  0.642217   0.663598   0.68278   0.0166326   \n",
       "49               XGBClassifier  0.647123   0.660039  0.671569   0.0100279   \n",
       "46               XGBClassifier  0.638569   0.659105  0.674423   0.0150954   \n",
       "44               XGBClassifier  0.638165   0.658038  0.671764   0.0143895   \n",
       "54               XGBClassifier  0.626771   0.657795  0.684513   0.0237686   \n",
       "18          LogisticRegression  0.649733   0.657387  0.664254  0.00595396   \n",
       "41               XGBClassifier  0.639221   0.655068  0.679489   0.0175216   \n",
       "53               XGBClassifier  0.644659   0.654368   0.66446  0.00808855   \n",
       "16          LogisticRegression  0.647284   0.654012  0.659938  0.00519716   \n",
       "43               XGBClassifier  0.632983   0.652917  0.683966   0.0222482   \n",
       "52               XGBClassifier   0.64166   0.652829  0.667628    0.010908   \n",
       "28          AdaBoostClassifier   0.63739   0.652134  0.672621   0.0149454   \n",
       "55               XGBClassifier   0.62613   0.651923  0.675265   0.0201339   \n",
       "29          AdaBoostClassifier  0.629061   0.650791  0.680407   0.0216914   \n",
       "14          LogisticRegression  0.644392   0.649938  0.654643  0.00422702   \n",
       "50               XGBClassifier  0.631503   0.648598   0.66723   0.0146262   \n",
       "42               XGBClassifier  0.629236   0.648288  0.676895   0.0205964   \n",
       "51               XGBClassifier  0.634494   0.648201  0.663435   0.0118643   \n",
       "40               XGBClassifier  0.631743   0.646585  0.672962   0.0186999   \n",
       "32  GradientBoostingClassifier  0.637356   0.646445   0.65452  0.00704396   \n",
       "33  GradientBoostingClassifier  0.627588   0.645727   0.65667   0.0129173   \n",
       "12          LogisticRegression  0.640744   0.645269  0.648307  0.00326181   \n",
       "25      RandomForestClassifier   0.63048   0.643028  0.655882   0.0103727   \n",
       "24      RandomForestClassifier  0.634647    0.64184  0.648146  0.00554675   \n",
       "10          LogisticRegression  0.636669   0.639478   0.64096  0.00198744   \n",
       "31          AdaBoostClassifier  0.625428   0.639413  0.656456   0.0128502   \n",
       "57               XGBClassifier  0.624413    0.63828  0.646998  0.00991314   \n",
       "27      RandomForestClassifier  0.627038     0.6357  0.645651  0.00765319   \n",
       "56               XGBClassifier  0.621285   0.634997  0.644041  0.00985945   \n",
       "26      RandomForestClassifier  0.632991   0.634444   0.63731  0.00202622   \n",
       "35  GradientBoostingClassifier  0.609968   0.633701  0.651276    0.017417   \n",
       "58               XGBClassifier  0.620323    0.63332  0.643394  0.00964258   \n",
       "34  GradientBoostingClassifier  0.609563   0.633288  0.659287   0.0203634   \n",
       "8           LogisticRegression  0.631007   0.632557  0.633822  0.00116706   \n",
       "30          AdaBoostClassifier  0.615653   0.630839  0.656448   0.0182129   \n",
       "59               XGBClassifier  0.616015   0.629901  0.640042   0.0101598   \n",
       "6           LogisticRegression  0.622963   0.623981  0.624864  0.00078193   \n",
       "20      RandomForestClassifier  0.616019   0.621422  0.627187  0.00456651   \n",
       "37               XGBClassifier  0.601238   0.621298  0.635133    0.014521   \n",
       "39               XGBClassifier  0.598575   0.620451  0.634188   0.0156371   \n",
       "23      RandomForestClassifier  0.607781   0.617884  0.623265  0.00714847   \n",
       "22      RandomForestClassifier  0.608873    0.61757  0.624068  0.00639561   \n",
       "21      RandomForestClassifier  0.604897   0.615615  0.625825  0.00855122   \n",
       "4           LogisticRegression  0.611492   0.613841  0.616134  0.00189535   \n",
       "36               XGBClassifier  0.591829    0.61324  0.624615   0.0151501   \n",
       "38               XGBClassifier  0.587403   0.611857  0.624776   0.0173008   \n",
       "2           LogisticRegression   0.59507   0.600744  0.607251  0.00500754   \n",
       "3           LogisticRegression  0.572741    0.58497  0.600345   0.0114865   \n",
       "19          LogisticRegression  0.578612   0.584058   0.59437  0.00729547   \n",
       "17          LogisticRegression  0.575198   0.582986  0.590127  0.00611192   \n",
       "7           LogisticRegression  0.568709   0.581148  0.597888   0.0122941   \n",
       "13          LogisticRegression  0.571976   0.580722  0.589242  0.00705039   \n",
       "5           LogisticRegression  0.574723   0.580676  0.591874  0.00792391   \n",
       "15          LogisticRegression  0.574433   0.580085  0.585197  0.00441125   \n",
       "9           LogisticRegression  0.577337   0.578539  0.580863   0.0016435   \n",
       "11          LogisticRegression  0.571408   0.577469  0.582061   0.0044716   \n",
       "0           LogisticRegression       NaN        NaN       NaN         NaN   \n",
       "1           LogisticRegression       NaN        NaN       NaN         NaN   \n",
       "\n",
       "           C learning_rate max_depth min_child_weight min_samples_split  \\\n",
       "45       NaN           0.3         1                2               NaN   \n",
       "48       NaN           0.3         3                2               NaN   \n",
       "47       NaN           0.3         1               10               NaN   \n",
       "49       NaN           0.3         3                2               NaN   \n",
       "46       NaN           0.3         1               10               NaN   \n",
       "44       NaN           0.3         1                2               NaN   \n",
       "54       NaN             1         1               10               NaN   \n",
       "18         2           NaN       NaN              NaN               NaN   \n",
       "41       NaN          0.05         3                2               NaN   \n",
       "53       NaN             1         1                2               NaN   \n",
       "16   1.77778           NaN       NaN              NaN               NaN   \n",
       "43       NaN          0.05         3               10               NaN   \n",
       "52       NaN             1         1                2               NaN   \n",
       "28       NaN           0.3       NaN              NaN               NaN   \n",
       "55       NaN             1         1               10               NaN   \n",
       "29       NaN           0.3       NaN              NaN               NaN   \n",
       "14   1.55556           NaN       NaN              NaN               NaN   \n",
       "50       NaN           0.3         3               10               NaN   \n",
       "42       NaN          0.05         3               10               NaN   \n",
       "51       NaN           0.3         3               10               NaN   \n",
       "40       NaN          0.05         3                2               NaN   \n",
       "32       NaN           0.8       NaN              NaN               NaN   \n",
       "33       NaN           0.8       NaN              NaN               NaN   \n",
       "12   1.33333           NaN       NaN              NaN               NaN   \n",
       "25       NaN           NaN         3              NaN                 5   \n",
       "24       NaN           NaN         3              NaN                 5   \n",
       "10   1.11111           NaN       NaN              NaN               NaN   \n",
       "31       NaN             1       NaN              NaN               NaN   \n",
       "57       NaN             1         3                2               NaN   \n",
       "27       NaN           NaN         3              NaN                10   \n",
       "56       NaN             1         3                2               NaN   \n",
       "26       NaN           NaN         3              NaN                10   \n",
       "35       NaN             1       NaN              NaN               NaN   \n",
       "58       NaN             1         3               10               NaN   \n",
       "34       NaN             1       NaN              NaN               NaN   \n",
       "8   0.888889           NaN       NaN              NaN               NaN   \n",
       "30       NaN             1       NaN              NaN               NaN   \n",
       "59       NaN             1         3               10               NaN   \n",
       "6   0.666667           NaN       NaN              NaN               NaN   \n",
       "20       NaN           NaN         1              NaN                 5   \n",
       "37       NaN          0.05         1                2               NaN   \n",
       "39       NaN          0.05         1               10               NaN   \n",
       "23       NaN           NaN         1              NaN                10   \n",
       "22       NaN           NaN         1              NaN                10   \n",
       "21       NaN           NaN         1              NaN                 5   \n",
       "4   0.444444           NaN       NaN              NaN               NaN   \n",
       "36       NaN          0.05         1                2               NaN   \n",
       "38       NaN          0.05         1               10               NaN   \n",
       "2   0.222222           NaN       NaN              NaN               NaN   \n",
       "3   0.222222           NaN       NaN              NaN               NaN   \n",
       "19         2           NaN       NaN              NaN               NaN   \n",
       "17   1.77778           NaN       NaN              NaN               NaN   \n",
       "7   0.666667           NaN       NaN              NaN               NaN   \n",
       "13   1.33333           NaN       NaN              NaN               NaN   \n",
       "5   0.444444           NaN       NaN              NaN               NaN   \n",
       "15   1.55556           NaN       NaN              NaN               NaN   \n",
       "9   0.888889           NaN       NaN              NaN               NaN   \n",
       "11   1.11111           NaN       NaN              NaN               NaN   \n",
       "0          0           NaN       NaN              NaN               NaN   \n",
       "1          0           NaN       NaN              NaN               NaN   \n",
       "\n",
       "   n_estimators     solver  \n",
       "45          162        NaN  \n",
       "48          120        NaN  \n",
       "47          162        NaN  \n",
       "49          162        NaN  \n",
       "46          120        NaN  \n",
       "44          120        NaN  \n",
       "54          120        NaN  \n",
       "18          NaN  liblinear  \n",
       "41          162        NaN  \n",
       "53          162        NaN  \n",
       "16          NaN  liblinear  \n",
       "43          162        NaN  \n",
       "52          120        NaN  \n",
       "28          120        NaN  \n",
       "55          162        NaN  \n",
       "29          162        NaN  \n",
       "14          NaN  liblinear  \n",
       "50          120        NaN  \n",
       "42          120        NaN  \n",
       "51          162        NaN  \n",
       "40          120        NaN  \n",
       "32          120        NaN  \n",
       "33          162        NaN  \n",
       "12          NaN  liblinear  \n",
       "25          162        NaN  \n",
       "24          120        NaN  \n",
       "10          NaN  liblinear  \n",
       "31          162        NaN  \n",
       "57          162        NaN  \n",
       "27          162        NaN  \n",
       "56          120        NaN  \n",
       "26          120        NaN  \n",
       "35          162        NaN  \n",
       "58          120        NaN  \n",
       "34          120        NaN  \n",
       "8           NaN  liblinear  \n",
       "30          120        NaN  \n",
       "59          162        NaN  \n",
       "6           NaN  liblinear  \n",
       "20          120        NaN  \n",
       "37          162        NaN  \n",
       "39          162        NaN  \n",
       "23          162        NaN  \n",
       "22          120        NaN  \n",
       "21          162        NaN  \n",
       "4           NaN  liblinear  \n",
       "36          120        NaN  \n",
       "38          120        NaN  \n",
       "2           NaN  liblinear  \n",
       "3           NaN      lbfgs  \n",
       "19          NaN      lbfgs  \n",
       "17          NaN      lbfgs  \n",
       "7           NaN      lbfgs  \n",
       "13          NaN      lbfgs  \n",
       "5           NaN      lbfgs  \n",
       "15          NaN      lbfgs  \n",
       "9           NaN      lbfgs  \n",
       "11          NaN      lbfgs  \n",
       "0           NaN  liblinear  \n",
       "1           NaN      lbfgs  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper3.score_summary(sort_by='mean_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model is XGBoost with learning_rate=.05, max_depth=1 , min_child_weight=10 and 307 features set2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on training data:  83.483%\n",
      "AUC on test data:  64.813%\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.3,n_estimators=162,max_depth=1,min_child_weight=2).fit(X_train_s3, y_train_s3)\n",
    "#,gamma=0.1,colsample_bytree=0.3\n",
    "y_train_preds = xgb.predict_proba(X_train_s3)[:,1]\n",
    "y_valid_preds = xgb.predict_proba(X_valid_s3)[:,1]\n",
    "\n",
    "auc_train = roc_auc_score(y_train_s3, y_train_preds)\n",
    "auc_valid = roc_auc_score(y_valid_s3, y_valid_preds)\n",
    "\n",
    "print (\"AUC on training data: \",\"{0:.3%}\".format(auc_train))\n",
    "print (\"AUC on test data: \",\"{0:.3%}\".format(auc_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-391-31829fb7ee6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# logistic regression using 162 subset3 of features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf_lo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.889\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_s3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_s3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_train_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_lo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_s3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_valid_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_lo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_s3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   2083\u001b[0m                       \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m                       )\n\u001b[0;32m-> 2085\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_encoded_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2086\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m             for l1_ratio in l1_ratios_)\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_log_reg_scoring_path\u001b[0;34m(X, y, train, test, pos_class, Cs, scoring, fit_intercept, max_iter, tol, class_weight, verbose, solver, penalty, dual, intercept_scaling, multi_class, random_state, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_scaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         max_squared_sum=max_squared_sum, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[0mlog_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0mcoefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m     \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "# logistic regression using 162 subset3 of features\n",
    "clf_lo = LogisticRegressionCV(Cs=0.889, penalty='l2', solver='liblinear', cv=3).fit(X_train_s3,y_train_s3)\n",
    "\n",
    "y_train_preds = clf_lo.predict_proba(X_train_s3)[:,1]\n",
    "y_valid_preds = clf_lo.predict_proba(X_valid_s3)[:,1]\n",
    "\n",
    "auc_train = roc_auc_score(y_train_s3, y_train_preds)\n",
    "auc_valid = roc_auc_score(y_valid_s3, y_valid_preds)\n",
    "\n",
    "print (\"AUC on training data: \",\"{0:.3%}\".format(auc_train))\n",
    "print (\"AUC on test data: \",\"{0:.3%}\".format(auc_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on training data:  81.585%\n",
      "AUC on test data:  67.653%\n"
     ]
    }
   ],
   "source": [
    "# logistic regression using all 3036 features\n",
    "clf_lo = LogisticRegressionCV(penalty='l2',C=0.89,solver='liblinear',).fit(X_train_all,y_train_all)\n",
    "\n",
    "y_train_preds = clf_lo.predict_proba(X_train_all)[:,1]\n",
    "y_valid_preds = clf_lo.predict_proba(X_valid_all)[:,1]\n",
    "\n",
    "auc_train = roc_auc_score(y_train_all, y_train_preds)\n",
    "auc_valid = roc_auc_score(y_valid_all, y_valid_preds)\n",
    "\n",
    "print (\"AUC on training data: \",\"{0:.3%}\".format(auc_train))\n",
    "print (\"AUC on test data: \",\"{0:.3%}\".format(auc_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the threshold probability with the highest F score using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.6143931256713212\n",
      "Balanced accuracy score:  0.6145839102102602\n",
      "Threshold probability with best F-score :  0.23 0.77 beta =  1.5\n"
     ]
    }
   ],
   "source": [
    "y_true = y_valid_s3.reset_index(drop=True)\n",
    "y_valid_class = (y_valid_preds >= 0.5).astype(int)\n",
    "thresholds=np.arange(0,1,.01)\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_valid_class)\n",
    "print('Accuracy score: ',accuracy)\n",
    "\n",
    "baccuracy = balanced_accuracy_score(y_true, y_valid_class)\n",
    "print('Balanced accuracy score: ',baccuracy)\n",
    "\n",
    "beta, best_threshold, best_fscore, fscores_thres_pairs, adj_class, fscores = \\\n",
    "                    create_fbeta_score(y_true=y_true, y_valid_preds=y_valid_preds, thresholds=thresholds, beta=1.5)\n",
    " \n",
    "print (\"Threshold probability with best F-score : \",  round(best_threshold,2), \n",
    "       round(best_fscore,2), \"beta = \", beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beta_v1, best_threshold_v1, best_fscore_v1, fscores_thres_pairs_v1, adj_class_v1, fscores_v1= \\\n",
    "            create_fbeta_score(y_true=y_true, y_valid_preds=y_valid_preds, thresholds=thresholds, beta=1)\n",
    "beta_v2, best_threshold_v2, best_fscore_v2, fscores_thres_pairs_v2, adj_class_v2, fscores_v2 = \\\n",
    "            create_fbeta_score(y_true=y_true, y_valid_preds=y_valid_preds, thresholds=thresholds, beta=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta =  1  threshold =  0.31  best_fscore =  0.676056338028169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.08      0.15       463\n",
      "         1.0       0.52      0.97      0.68       468\n",
      "\n",
      "    accuracy                           0.53       931\n",
      "   macro avg       0.64      0.53      0.41       931\n",
      "weighted avg       0.64      0.53      0.41       931\n",
      "\n",
      "tn:  38 fp:  425 fn:  12 tp:  456 \n",
      "\n",
      "beta =  1.5  threshold =  0.23  best_fscore =  0.7689585439838219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.01      0.03       463\n",
      "         1.0       0.51      1.00      0.67       468\n",
      "\n",
      "    accuracy                           0.51       931\n",
      "   macro avg       0.75      0.51      0.35       931\n",
      "weighted avg       0.75      0.51      0.35       931\n",
      "\n",
      "tn:  6 fp:  457 fn:  0 tp:  468\n"
     ]
    }
   ],
   "source": [
    "print('beta = ',beta_v1, ' threshold = ',best_threshold_v1, ' best_fscore = ',best_fscore_v1)\n",
    "print(classification_report(y_true, adj_class_v1))\n",
    "\n",
    "tn_v1, fp_v1, fn_v1, tp_v1 = (confusion_matrix(y_true, adj_class_v1).ravel())\n",
    "print('tn: ',tn_v1,'fp: ',fp_v1,'fn: ',fn_v1,'tp: ',tp_v1,'\\n')\n",
    "\n",
    "print('beta = ',beta_v2, ' threshold = ',best_threshold_v2, ' best_fscore = ',best_fscore_v2)\n",
    "print(classification_report(y_true, adj_class_v2))\n",
    "\n",
    "tn_v2, fp_v2, fn_v2, tp_v2 = (confusion_matrix(y_true, adj_class_v2).ravel())\n",
    "print('tn: ',tn_v2,'fp: ',fp_v2,'fn: ',fn_v2,'tp: ',tp_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(thresholds, fscores_v1, color='blue')\n",
    "plt.plot(thresholds, fscores_v2, color='red')\n",
    "plt.title('F Beta Score Curves')\n",
    "#plt.legend(('F Beta 1', 'F Beta 2'))\n",
    "plt.xlabel('Threshold')\n",
    "plt.axvline(x=best_threshold_v1, color='blue')\n",
    "plt.text(best_threshold_v1,.71,'Optimal Threshold Beta 1',rotation=90)\n",
    "plt.axvline(x=best_threshold_v2, color='red')\n",
    "plt.text(best_threshold_v2,.73,'Optimal Threshold Beta 2',rotation=90)\n",
    "plt.ylabel('F Beta Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.639344262295082"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true, adj_class_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.22222222, 0.44444444, 0.66666667, 0.88888889,\n",
       "       1.11111111, 1.33333333, 1.55555556, 1.77777778, 2.        ])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(start = 0, stop = 2, num = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "474px",
    "left": "1331px",
    "right": "20px",
    "top": "120px",
    "width": "513px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
